package com.atguigu.api.sink;

import com.alibaba.fastjson.JSON;
import com.atguigu.function.ClickSource;
import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.connector.base.DeliveryGuarantee;
import org.apache.flink.connector.kafka.sink.KafkaRecordSerializationSchema;
import org.apache.flink.connector.kafka.sink.KafkaSink;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

/**
 * è¾“å‡ºåˆ°kafka
 */
public class Flink02_SinkKafka {
    public static void main(String[] args) throws Exception {
        //åˆ›å»ºæµå¼å¤„ç†
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        //è®¾ç½®å…¨å±€å¹¶è¡Œåº¦ï¼šä¸è®¾ç½®é»˜è®¤ä¸ºå…¨å¹¶è¡Œåº¦ï¼›1ä¸ºå•çº¿ç¨‹æ‰§è¡Œ
        env.setParallelism(1);

        //å¼€å¯æ£€æŸ¥ç‚¹
        env.enableCheckpointing(5000);

        KafkaSink<String> build = KafkaSink
                .<String>builder()
                .setBootstrapServers("hadoop102:9092,hadoop103:9092,hadoop104:9092")
                .setRecordSerializer(
                        KafkaRecordSerializationSchema
                                .builder()
                                .setTopic("topic_db") //è®¾ç½®ä¸»é¢˜
                                .setValueSerializationSchema(new SimpleStringSchema())  //è®¾ç½®åºåˆ—åŒ–
                                .build()
                )
                .setDeliveryGuarantee(DeliveryGuarantee.AT_LEAST_ONCE)
                //å¦‚æœğŸ‘†æ˜¯ç²¾ç¡®ä¸€æ¬¡ï¼Œåˆ™å¿…é¡»è®¾ç½®äº‹åŠ¡IDï¼šğŸ‘‡
                .setTransactionalIdPrefix("flink")
                .build();

        env
                .addSource(new ClickSource())
                .map(JSON::toJSONString)
                .sinkTo(build);

        //å¯åŠ¨ç¨‹åºæ‰§è¡Œ
        env.execute();
    }
}
